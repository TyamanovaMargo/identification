{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TyamanovaMargo/identification/blob/main/%22BERT_MULTICLASSIFICATION_GENRE_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "len8Qi91y5FX",
        "outputId": "1a459766-5bc0-4398-d3cc-bf055b8e163b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wget\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=ca9d7955871b9e3e617156cc2da484400e15708f007035c986f3a4f24670e12a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QA9w6dbwfzz"
      },
      "source": [
        "# BERT Fine Tuning for Multi Class Text Classification\n",
        "\n",
        "This notebook contains code to fine tune a pretrained BERT language model to a specific classification task.\n",
        "As BERT model interface the Huggingface library with a PyTorch backend is used.\n",
        "\n",
        "In this notebook, the model has been fine tuned with the German 10kGNAD Dataset but could easily be fine tuned on any other classification dataset.\n",
        "\n",
        "The code was implemented based on the huggingface example scripts for glue tasks fine tuning (https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128) and the blog post by Chris McCormick (http://mccormickml.com/2019/07/22/BERT-fine-tuning/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKjjVxVDKsS1"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoConfig\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import seaborn as sns\n",
        "import IPython\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZxf_D2gAdTO"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKGW39P8fm33",
        "outputId": "63ef35ac-46a5-4609-ac97-78d68ab3f6f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJzGKGLX9AxN"
      },
      "source": [
        "# Download dataset\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Multiclassification_dataset/dataset_all_pos_dir_multiclass_low_case.csv\",\n",
        "#                  encoding=\"utf-8\",\n",
        "#                  header=0)\n",
        "\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Multiclassification_dataset/dataset_all_pos_dir_multiclass.csv\",\n",
        "#                  encoding=\"utf-8\",\n",
        "#                  header=0)\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Multiclassification_dataset/dataset_all_pos_dir_multiclass_first_chunk.csv\",\n",
        "                 encoding=\"utf-8\",\n",
        "                 header=0)\n",
        "\n",
        "# Download dataset without punctuation\n",
        "# df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Multiclassification_dataset/dataset_all_pos_dir_multiclass_without_punc_FILTERED_nun.csv',\n",
        "#                 encoding=\"utf-8\")\n",
        "#                 #  skiprows=1,)\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kREGRbGkQDL8",
        "outputId": "af5b4486-198a-407c-e8a8-406b962e4079"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  Дом потерянных душ Романтические детективы Евг...      0\n",
            "1  Стихи для мертвецов Дуглас Престон Звезды миро...      0\n",
            "2  Сказка о смерти Мартен С. Снейдер #3 В Берне о...      0\n",
            "3  Темная материя Город в Нигде Джейсон Дессен, в...      0\n",
            "4  Позже Темная башня (АСТ) Джейми Конклин, живущ...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuN3olL1s1R0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d5b8dc-4299-45ca-8b5b-957fdded3e86"
      },
      "source": [
        "texts = df.text.values\n",
        "label_cats = df.label.astype('category').cat\n",
        "print(label_cats)\n",
        "# List of label names (str)\n",
        "label_names = label_cats.categories\n",
        "print(label_names)\n",
        "# List of label ids (int, in range (0,num_classes-1))\n",
        "labels = label_cats.codes\n",
        "print(labels)\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pandas.core.arrays.categorical.CategoricalAccessor object at 0x7db0fafb1b90>\n",
            "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype='int64')\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "        ..\n",
            "7329    10\n",
            "7330    10\n",
            "7331    10\n",
            "7332    10\n",
            "7333    10\n",
            "Length: 7334, dtype: int8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label Names (should be 0 to 10):\", label_names)\n",
        "print(\"Labels (should match Label Names):\", labels[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1SZFliXIOpx",
        "outputId": "0951e6f9-61b5-40ef-ab00-c7774099f6c7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Names (should be 0 to 10): Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype='int64')\n",
            "Labels (should match Label Names): 0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "5    0\n",
            "6    0\n",
            "7    0\n",
            "8    0\n",
            "9    0\n",
            "dtype: int8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame (assuming you have loaded it already)\n",
        "# df = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Ensure that labels are correctly mapped and exclude any non-numeric entries\n",
        "label_cats = df.label.astype('category').cat\n",
        "label_names = label_cats.categories\n",
        "\n",
        "# Map labels to integers\n",
        "labels = label_cats.codes\n",
        "\n",
        "# Create a DataFrame with text and corresponding labels\n",
        "df_mapped = df.copy()\n",
        "df_mapped['label_mapped'] = labels\n",
        "\n",
        "# Print out the first few rows of the DataFrame to verify\n",
        "print(df_mapped[['text', 'label_mapped']].head())\n",
        "print(df_mapped[['text', 'label_mapped']].iloc[500:510])\n",
        "print(df_mapped[['text', 'label_mapped']].tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0_t6GpdLz6a",
        "outputId": "bb3d9ced-b6a7-4f7b-9019-20a781b6009a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label_mapped\n",
            "0  Дом потерянных душ Романтические детективы Евг...             0\n",
            "1  Стихи для мертвецов Дуглас Престон Звезды миро...             0\n",
            "2  Сказка о смерти Мартен С. Снейдер #3 В Берне о...             0\n",
            "3  Темная материя Город в Нигде Джейсон Дессен, в...             0\n",
            "4  Позже Темная башня (АСТ) Джейми Конклин, живущ...             0\n",
            "                                                  text  label_mapped\n",
            "500  Регуляторы Тэк #2 Прекрасный летний денек в ма...             0\n",
            "501  Девушка из моря Национальный бестселлер Британ...             0\n",
            "502  Убийственно жив Неизвестный маньяк не просто у...             0\n",
            "503  Мактуб. Ядовитый любовник Лана Мейер Восточные...             0\n",
            "504  Фирма Эта фирма погасила его кредит. Предостав...             0\n",
            "505  Летающие убийцы Спецназ ГРУ В горах Кавказа об...             0\n",
            "506  Игра с огнем (сборник) Звезды мирового детекти...             0\n",
            "507  Родная кровь В глубине штата Мэн, на берегу за...             0\n",
            "508  Ледовый патруль Арктическая база. Полярный спе...             0\n",
            "509  Надежда умирает последней Иностранный детектив...             0\n",
            "                                                   text  label_mapped\n",
            "7329  Беженец Trendbooks WOW Самая важная книга года...            10\n",
            "7330  Куриный бульон для души: 101 история о животны...            10\n",
            "7331  О чем весь город говорит В 1889 году молодой ш...            10\n",
            "7332  Удивительный зять Глава 1 Роскошная семейная в...            10\n",
            "7333  Самородок Перла Добрые книги для детей и взрос...            10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSsp_l_yoNJf"
      },
      "source": [
        "## Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UUTkMV4yDTY"
      },
      "source": [
        "# model_name = \"DeepPavlov/rubert-base-cased\"\n",
        "# model_name ='DeepPavlov/rubert-base-cased'\n",
        "model_name ='bert-base-multilingual-cased'\n",
        "MAX_INPUT_LENGTH = 512"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-OE6oDZoMIG",
        "outputId": "9657f28f-131e-4dfc-8324-da71a5ee88fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the pretrained BERT tokenizer.\n",
        "print(f\"Loading {model_name} tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading bert-base-multilingual-cased tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDkMb1urrIAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe325b4c-893e-4fdc-e808-8e3679940061"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_INPUT_LENGTH,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert lists to tensors\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Print the results for debugging\n",
        "print('Original Text:', texts[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Attention Mask:', attention_masks[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Дом потерянных душ Романтические детективы Евгении Кретовой #7 Аделия – потомственная ясновидящая. Во всяком случае, так написано на вывеске ее салона. Поток клиенток, гадания, натальные карты и никакой романтики. Но накануне праздников что-то идет не так: клиентка не может определиться с невестой для сына, проблемы у сестры, странный тип не оставляет Аделию в покое. В итоге она волей-неволей оказывается вовлечена в тайны чужой семейной жизни. Те самые, что обычно прячутся скелетами в шкафу. Романтика, остро приправленная мистикой и загадкой старого преступления – новый детектив от Евгении Кретовой. Дом потерянных душ Пролог Она шагнула к кромке воды, безразлично наблюдая, как темная вода лизнула покрасневшие пальцы на ногах. Потянула за край рубашки, стянула через голову и, не оглядываясь, отбросила прочь, в траву. И только тогда посмотрела через плечо. Шагнула в воду. Ноги скользили по вязкой глине, приходилось цепляться за камыш, пробираться сквозь него осторожно, зябко ежась от ледяных брызг. Шаг за шагом – до шаткого помоста, что упирался подгнившими досками в озерную гладь. Зацепилась рукой за скользкие, облепленные тиной и водорослями доски. И, оттолкнувшись от топкой глины, сделала два гребка от берега. И только тогда оглянулась, посмотрела упрямо. Черная озерная гладь ловила блики заходящего солнца. Неяркого, уже пропитанного золотом надвигающейся осени. Еще один гребок спиной вперед, тихо, как учил когда-то отец. Чтобы не разбудить озерных ду?хов – так говорила мать. Взгляд неотступно следил за тем, кто следовал за ней. Улыбался по-детски криво и наивно. Смотрел жадно и надеялся на игру. Она зло плеснула водой в прозрачно-серые глаза и отплыла к берегу, с удовольствием наблюдая, как темная вода всколыхнулась от ее движения, как закрутилась водоворотом, увлекая неумелую жертву. Как безвольно вскинулись над поверхностью белые руки в мелких, будто манная крупа, веснушках, как узкое лицо накрыло гребнем черной волны, выдавив из легких прощальный крик. В эти последние летние дни озерные омуты подбираются к самому берегу. Глава 1. Салон «Луноликая» Москва, конец декабря, наши дни – Я все-таки не вижу у вас серьезных проблем, – деловитый голос из кабинета, запах восковых свечей и – тонкий, едва уловимый – ла?дана. Таисия подобралась, на цыпочках отошла к своему рабочему месту, взяла телефонную трубку. Сообщила шепотом: – Нет, госпожа АделияМило? сейчас занята и подойти к телефону не может. Тихий голос там, на другом конце провода, прошелестел: – У меня срочный, не терпящий отлагательств вопрос. Госпожа Аделия уверяла, что я смогу его решить, не приезжая к ней повторно. Таисия почесала кончик носа, отозвалась доверительно: – Боюсь, это как раз тот случай, когда заверения бесполезны.\n",
            "Token IDs: tensor([   101,  37106,  10297,  15469,  18971,  10970,  11576,  11148,  36314,\n",
            "         65446,  89353,  59990,  18221,    514,  10541,  14276,  11905,    519,\n",
            "         40035,  17780,    108,    128,    509,  44030,  11502,    100,  37706,\n",
            "         48310,  96947,  53156,  10385,  26325,    119,  12624,  72782,  13393,\n",
            "         28127,    117,  12123,  10122,  48680,  10122,  96195,  14149,  14430,\n",
            "         75431,  10868,  35551,  10179,    119,  11480,  20422,    551,  10783,\n",
            "         28252,  11899,    117,  16616,  72216,    117,  10122,  44422,  34045,\n",
            "         73985,    549,  19544,  67967,  10384,  25122,  31399,    119,  19732,\n",
            "         10122,  17343,  86622,  59784,  41637,  10433,  10791,    118,  11663,\n",
            "           549,  82635,  10375,  12123,    131,    551,  10783,  28252,  10521,\n",
            "         10375,  16087,    555,  35415,  87097, 106364,  10625,    558,  10375,\n",
            "         14149,  98526,  10520,  37060,    117,  44536,    560,  10277,  95212,\n",
            "           117,  32619,  11092,  20844,  10375,  85854,  36829,  29061,    509,\n",
            "         44030,  13564,    543,  10297,  30091,    119,    511,  45184,  13976,\n",
            "         10439,  20929,    118,  10375, 110687,  11742, 102128,  10439,  10541,\n",
            "         11851,  26724,    543,  10475,  69657,  59172,  52834,  10384,  67338,\n",
            "         11075,  17237,    119,  39968, 109550,    117,  10791,  32654,  25484,\n",
            "         65891,  19691,  10625,    558,  11557,  67033,  10508,    543,    565,\n",
            "         10521,  58899,    119,  36314,  24612,    117,  85854,  62735,  10913,\n",
            "        108877,  11548,  37140,  12189,  14397,    549,  10234,  11347,  10746,\n",
            "         14397, 101433,  38494,  77214,    100,  30994,  89353,  59990,  10541,\n",
            "         10332,    514,  10541,  14276,  11905,    519,  40035,  17780,    119,\n",
            "         37106,  10297,  15469,  18971,  10970,  11576,  11148,  35475,  22141,\n",
            "         25428,  79703,  10823, 103614,    551,    551,  21178,  11557,  37634,\n",
            "           117,  13012,  34556,  70667,  10122,  61394,  94811,  10385,    117,\n",
            "         10949,  19710,  11548,  30953,  33190,  11571, 103614,  10297,  10510,\n",
            "         56680,  10695,  55580,  12634,  12118,  12993,  10122,  11279,  82776,\n",
            "           119,  11480,  32127, 103614,  10234,  30213,    557,  83282,  20346,\n",
            "           117,  15888,  18971,  26428,  12798,  83603,    549,    117,  10375,\n",
            "           555,  41824,  10292,  24000,  11833,    117,  10332,  85584,  17969,\n",
            "         16610,  12709,  40697,    117,    543,    559,  41410,  10227,    119,\n",
            "           517,  13721,  31816,  10297,  10513, 104722,  67244,  10179,  12798,\n",
            "           556,  11851,  34521,    119,    533,  51229, 103614,    543,  54173,\n",
            "           119,  19732,  14122,    558,  48613,  10851,  14894,  10783,  10297,\n",
            "           543,  78070,  14397,  55367,  20563,    117, 109228,  15725,  11078,\n",
            "         61409,  10234,  62873,  23879,    117,  12709,  64815,  14133,    558,\n",
            "         10510,  15275,  42366,  13981,  85854,  18256,  10316,  24751,    117,\n",
            "           548,  10385,  12528,  11623,    546,  17254,  11833,  10332,  94693,\n",
            "         40887,  10970, 109300,  46073,  10823,    119,    533,  51229,  10234,\n",
            "         79703,  59828,    100,  10344,  79703,  71501,  10990,  96358,  33580,\n",
            "         10179,    117,  10791,    560,  89534,  17204,  11429,  10823,  60471,\n",
            "         43180,  10344,  12184,  10508,    543,    555,  58758,  12719,  55367,\n",
            "         20004,  10851,    119,  11712,  13317,  20785,  20292,  84043,  11292,\n",
            "         10234,    558,  48613,  10851,  67350,  10205,    117,  58742,  29749,\n",
            "         52045,  30176,  11075,    549,  79200,  97648, 102572,  21357,  10344,\n",
            "         11434,    119,    517,    117,  10332,  10752,  89068,  47695,  31770,\n",
            "         10332,  56575,  14397,  55367,  34652,    117,  61626,  10179,  12500,\n",
            "         55895,  59373,  10521,  10332,  73925,    119,    517,  13721,  31816,\n",
            "           555,  10823,  80318, 103452,    117,  10297,  10513, 104722,  67244,\n",
            "         10179,    560,  35415,  27429,  10316,    119,    532,  65674,  10385,\n",
            "           555,  58758,  11548,  55367,  20004,  10851,  30977,  50301,    542,\n",
            "         58956,  10234,  23089,  72090,  26367,  23716,    119,  21124,  59426,\n",
            "         18632,    117,  15530,  12709,  80465,  11240,  11050,  88615,  10241,\n",
            "         12614,  78465, 103270,  30305,  10625,  85854,  15065,    119,    514,\n",
            "         20904,  13713,  55895,  59373,  11899,    558,  20785,  11075,    543,\n",
            "         75556,    117,  43524,  10316,    117,  10949, 103510,  10517,  15283,\n",
            "           118,  11663,  34606,    119,  88303,  10375,  17257,    102])\n",
            "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.encode_plus(\n",
        "    texts[0],\n",
        "    add_special_tokens=True,\n",
        "    max_length=MAX_INPUT_LENGTH,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        "))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Gq2sJLK5Fk",
        "outputId": "26aeb41c-5225-449c-ada2-a705f09b16c6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   101,  37106,  10297,  15469,  18971,  10970,  11576,  11148,  36314,\n",
            "          65446,  89353,  59990,  18221,    514,  10541,  14276,  11905,    519,\n",
            "          40035,  17780,    108,    128,    509,  44030,  11502,    100,  37706,\n",
            "          48310,  96947,  53156,  10385,  26325,    119,  12624,  72782,  13393,\n",
            "          28127,    117,  12123,  10122,  48680,  10122,  96195,  14149,  14430,\n",
            "          75431,  10868,  35551,  10179,    119,  11480,  20422,    551,  10783,\n",
            "          28252,  11899,    117,  16616,  72216,    117,  10122,  44422,  34045,\n",
            "          73985,    549,  19544,  67967,  10384,  25122,  31399,    119,  19732,\n",
            "          10122,  17343,  86622,  59784,  41637,  10433,  10791,    118,  11663,\n",
            "            549,  82635,  10375,  12123,    131,    551,  10783,  28252,  10521,\n",
            "          10375,  16087,    555,  35415,  87097, 106364,  10625,    558,  10375,\n",
            "          14149,  98526,  10520,  37060,    117,  44536,    560,  10277,  95212,\n",
            "            117,  32619,  11092,  20844,  10375,  85854,  36829,  29061,    509,\n",
            "          44030,  13564,    543,  10297,  30091,    119,    511,  45184,  13976,\n",
            "          10439,  20929,    118,  10375, 110687,  11742, 102128,  10439,  10541,\n",
            "          11851,  26724,    543,  10475,  69657,  59172,  52834,  10384,  67338,\n",
            "          11075,  17237,    119,  39968, 109550,    117,  10791,  32654,  25484,\n",
            "          65891,  19691,  10625,    558,  11557,  67033,  10508,    543,    565,\n",
            "          10521,  58899,    119,  36314,  24612,    117,  85854,  62735,  10913,\n",
            "         108877,  11548,  37140,  12189,  14397,    549,  10234,  11347,  10746,\n",
            "          14397, 101433,  38494,  77214,    100,  30994,  89353,  59990,  10541,\n",
            "          10332,    514,  10541,  14276,  11905,    519,  40035,  17780,    119,\n",
            "          37106,  10297,  15469,  18971,  10970,  11576,  11148,  35475,  22141,\n",
            "          25428,  79703,  10823, 103614,    551,    551,  21178,  11557,  37634,\n",
            "            117,  13012,  34556,  70667,  10122,  61394,  94811,  10385,    117,\n",
            "          10949,  19710,  11548,  30953,  33190,  11571, 103614,  10297,  10510,\n",
            "          56680,  10695,  55580,  12634,  12118,  12993,  10122,  11279,  82776,\n",
            "            119,  11480,  32127, 103614,  10234,  30213,    557,  83282,  20346,\n",
            "            117,  15888,  18971,  26428,  12798,  83603,    549,    117,  10375,\n",
            "            555,  41824,  10292,  24000,  11833,    117,  10332,  85584,  17969,\n",
            "          16610,  12709,  40697,    117,    543,    559,  41410,  10227,    119,\n",
            "            517,  13721,  31816,  10297,  10513, 104722,  67244,  10179,  12798,\n",
            "            556,  11851,  34521,    119,    533,  51229, 103614,    543,  54173,\n",
            "            119,  19732,  14122,    558,  48613,  10851,  14894,  10783,  10297,\n",
            "            543,  78070,  14397,  55367,  20563,    117, 109228,  15725,  11078,\n",
            "          61409,  10234,  62873,  23879,    117,  12709,  64815,  14133,    558,\n",
            "          10510,  15275,  42366,  13981,  85854,  18256,  10316,  24751,    117,\n",
            "            548,  10385,  12528,  11623,    546,  17254,  11833,  10332,  94693,\n",
            "          40887,  10970, 109300,  46073,  10823,    119,    533,  51229,  10234,\n",
            "          79703,  59828,    100,  10344,  79703,  71501,  10990,  96358,  33580,\n",
            "          10179,    117,  10791,    560,  89534,  17204,  11429,  10823,  60471,\n",
            "          43180,  10344,  12184,  10508,    543,    555,  58758,  12719,  55367,\n",
            "          20004,  10851,    119,  11712,  13317,  20785,  20292,  84043,  11292,\n",
            "          10234,    558,  48613,  10851,  67350,  10205,    117,  58742,  29749,\n",
            "          52045,  30176,  11075,    549,  79200,  97648, 102572,  21357,  10344,\n",
            "          11434,    119,    517,    117,  10332,  10752,  89068,  47695,  31770,\n",
            "          10332,  56575,  14397,  55367,  34652,    117,  61626,  10179,  12500,\n",
            "          55895,  59373,  10521,  10332,  73925,    119,    517,  13721,  31816,\n",
            "            555,  10823,  80318, 103452,    117,  10297,  10513, 104722,  67244,\n",
            "          10179,    560,  35415,  27429,  10316,    119,    532,  65674,  10385,\n",
            "            555,  58758,  11548,  55367,  20004,  10851,  30977,  50301,    542,\n",
            "          58956,  10234,  23089,  72090,  26367,  23716,    119,  21124,  59426,\n",
            "          18632,    117,  15530,  12709,  80465,  11240,  11050,  88615,  10241,\n",
            "          12614,  78465, 103270,  30305,  10625,  85854,  15065,    119,    514,\n",
            "          20904,  13713,  55895,  59373,  11899,    558,  20785,  11075,    543,\n",
            "          75556,    117,  43524,  10316,    117,  10949, 103510,  10517,  15283,\n",
            "            118,  11663,  34606,    119,  88303,  10375,  17257,    102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):  # Check first 5 texts\n",
        "    print(f\"\\nOriginal Text {i}:\", texts[i])\n",
        "    print(f\"Token IDs {i}:\", input_ids[i])\n",
        "    print(f\"Attention Mask {i}:\", attention_masks[i])\n",
        "    print(f\"Number of 0s in Token IDs {i}:\", (input_ids[i] == 0).sum().item())\n",
        "    print(f\"Number of 0s in Attention Mask {i}:\", (attention_masks[i] == 0).sum().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7muuc0pSKWgX",
        "outputId": "a956d3d6-3b7d-427f-dee7-ab0342dbfe11"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Text 0: Дом потерянных душ Романтические детективы Евгении Кретовой #7 Аделия – потомственная ясновидящая. Во всяком случае, так написано на вывеске ее салона. Поток клиенток, гадания, натальные карты и никакой романтики. Но накануне праздников что-то идет не так: клиентка не может определиться с невестой для сына, проблемы у сестры, странный тип не оставляет Аделию в покое. В итоге она волей-неволей оказывается вовлечена в тайны чужой семейной жизни. Те самые, что обычно прячутся скелетами в шкафу. Романтика, остро приправленная мистикой и загадкой старого преступления – новый детектив от Евгении Кретовой. Дом потерянных душ Пролог Она шагнула к кромке воды, безразлично наблюдая, как темная вода лизнула покрасневшие пальцы на ногах. Потянула за край рубашки, стянула через голову и, не оглядываясь, отбросила прочь, в траву. И только тогда посмотрела через плечо. Шагнула в воду. Ноги скользили по вязкой глине, приходилось цепляться за камыш, пробираться сквозь него осторожно, зябко ежась от ледяных брызг. Шаг за шагом – до шаткого помоста, что упирался подгнившими досками в озерную гладь. Зацепилась рукой за скользкие, облепленные тиной и водорослями доски. И, оттолкнувшись от топкой глины, сделала два гребка от берега. И только тогда оглянулась, посмотрела упрямо. Черная озерная гладь ловила блики заходящего солнца. Неяркого, уже пропитанного золотом надвигающейся осени. Еще один гребок спиной вперед, тихо, как учил когда-то отец. Чтобы не разбудить озерных ду?хов – так говорила мать. Взгляд неотступно следил за тем, кто следовал за ней. Улыбался по-детски криво и наивно. Смотрел жадно и надеялся на игру. Она зло плеснула водой в прозрачно-серые глаза и отплыла к берегу, с удовольствием наблюдая, как темная вода всколыхнулась от ее движения, как закрутилась водоворотом, увлекая неумелую жертву. Как безвольно вскинулись над поверхностью белые руки в мелких, будто манная крупа, веснушках, как узкое лицо накрыло гребнем черной волны, выдавив из легких прощальный крик. В эти последние летние дни озерные омуты подбираются к самому берегу. Глава 1. Салон «Луноликая» Москва, конец декабря, наши дни – Я все-таки не вижу у вас серьезных проблем, – деловитый голос из кабинета, запах восковых свечей и – тонкий, едва уловимый – ла?дана. Таисия подобралась, на цыпочках отошла к своему рабочему месту, взяла телефонную трубку. Сообщила шепотом: – Нет, госпожа АделияМило? сейчас занята и подойти к телефону не может. Тихий голос там, на другом конце провода, прошелестел: – У меня срочный, не терпящий отлагательств вопрос. Госпожа Аделия уверяла, что я смогу его решить, не приезжая к ней повторно. Таисия почесала кончик носа, отозвалась доверительно: – Боюсь, это как раз тот случай, когда заверения бесполезны.\n",
            "Token IDs 0: tensor([   101,  37106,  10297,  15469,  18971,  10970,  11576,  11148,  36314,\n",
            "         65446,  89353,  59990,  18221,    514,  10541,  14276,  11905,    519,\n",
            "         40035,  17780,    108,    128,    509,  44030,  11502,    100,  37706,\n",
            "         48310,  96947,  53156,  10385,  26325,    119,  12624,  72782,  13393,\n",
            "         28127,    117,  12123,  10122,  48680,  10122,  96195,  14149,  14430,\n",
            "         75431,  10868,  35551,  10179,    119,  11480,  20422,    551,  10783,\n",
            "         28252,  11899,    117,  16616,  72216,    117,  10122,  44422,  34045,\n",
            "         73985,    549,  19544,  67967,  10384,  25122,  31399,    119,  19732,\n",
            "         10122,  17343,  86622,  59784,  41637,  10433,  10791,    118,  11663,\n",
            "           549,  82635,  10375,  12123,    131,    551,  10783,  28252,  10521,\n",
            "         10375,  16087,    555,  35415,  87097, 106364,  10625,    558,  10375,\n",
            "         14149,  98526,  10520,  37060,    117,  44536,    560,  10277,  95212,\n",
            "           117,  32619,  11092,  20844,  10375,  85854,  36829,  29061,    509,\n",
            "         44030,  13564,    543,  10297,  30091,    119,    511,  45184,  13976,\n",
            "         10439,  20929,    118,  10375, 110687,  11742, 102128,  10439,  10541,\n",
            "         11851,  26724,    543,  10475,  69657,  59172,  52834,  10384,  67338,\n",
            "         11075,  17237,    119,  39968, 109550,    117,  10791,  32654,  25484,\n",
            "         65891,  19691,  10625,    558,  11557,  67033,  10508,    543,    565,\n",
            "         10521,  58899,    119,  36314,  24612,    117,  85854,  62735,  10913,\n",
            "        108877,  11548,  37140,  12189,  14397,    549,  10234,  11347,  10746,\n",
            "         14397, 101433,  38494,  77214,    100,  30994,  89353,  59990,  10541,\n",
            "         10332,    514,  10541,  14276,  11905,    519,  40035,  17780,    119,\n",
            "         37106,  10297,  15469,  18971,  10970,  11576,  11148,  35475,  22141,\n",
            "         25428,  79703,  10823, 103614,    551,    551,  21178,  11557,  37634,\n",
            "           117,  13012,  34556,  70667,  10122,  61394,  94811,  10385,    117,\n",
            "         10949,  19710,  11548,  30953,  33190,  11571, 103614,  10297,  10510,\n",
            "         56680,  10695,  55580,  12634,  12118,  12993,  10122,  11279,  82776,\n",
            "           119,  11480,  32127, 103614,  10234,  30213,    557,  83282,  20346,\n",
            "           117,  15888,  18971,  26428,  12798,  83603,    549,    117,  10375,\n",
            "           555,  41824,  10292,  24000,  11833,    117,  10332,  85584,  17969,\n",
            "         16610,  12709,  40697,    117,    543,    559,  41410,  10227,    119,\n",
            "           517,  13721,  31816,  10297,  10513, 104722,  67244,  10179,  12798,\n",
            "           556,  11851,  34521,    119,    533,  51229, 103614,    543,  54173,\n",
            "           119,  19732,  14122,    558,  48613,  10851,  14894,  10783,  10297,\n",
            "           543,  78070,  14397,  55367,  20563,    117, 109228,  15725,  11078,\n",
            "         61409,  10234,  62873,  23879,    117,  12709,  64815,  14133,    558,\n",
            "         10510,  15275,  42366,  13981,  85854,  18256,  10316,  24751,    117,\n",
            "           548,  10385,  12528,  11623,    546,  17254,  11833,  10332,  94693,\n",
            "         40887,  10970, 109300,  46073,  10823,    119,    533,  51229,  10234,\n",
            "         79703,  59828,    100,  10344,  79703,  71501,  10990,  96358,  33580,\n",
            "         10179,    117,  10791,    560,  89534,  17204,  11429,  10823,  60471,\n",
            "         43180,  10344,  12184,  10508,    543,    555,  58758,  12719,  55367,\n",
            "         20004,  10851,    119,  11712,  13317,  20785,  20292,  84043,  11292,\n",
            "         10234,    558,  48613,  10851,  67350,  10205,    117,  58742,  29749,\n",
            "         52045,  30176,  11075,    549,  79200,  97648, 102572,  21357,  10344,\n",
            "         11434,    119,    517,    117,  10332,  10752,  89068,  47695,  31770,\n",
            "         10332,  56575,  14397,  55367,  34652,    117,  61626,  10179,  12500,\n",
            "         55895,  59373,  10521,  10332,  73925,    119,    517,  13721,  31816,\n",
            "           555,  10823,  80318, 103452,    117,  10297,  10513, 104722,  67244,\n",
            "         10179,    560,  35415,  27429,  10316,    119,    532,  65674,  10385,\n",
            "           555,  58758,  11548,  55367,  20004,  10851,  30977,  50301,    542,\n",
            "         58956,  10234,  23089,  72090,  26367,  23716,    119,  21124,  59426,\n",
            "         18632,    117,  15530,  12709,  80465,  11240,  11050,  88615,  10241,\n",
            "         12614,  78465, 103270,  30305,  10625,  85854,  15065,    119,    514,\n",
            "         20904,  13713,  55895,  59373,  11899,    558,  20785,  11075,    543,\n",
            "         75556,    117,  43524,  10316,    117,  10949, 103510,  10517,  15283,\n",
            "           118,  11663,  34606,    119,  88303,  10375,  17257,    102])\n",
            "Attention Mask 0: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Number of 0s in Token IDs 0: 0\n",
            "Number of 0s in Attention Mask 0: 0\n",
            "\n",
            "Original Text 1: Стихи для мертвецов Дуглас Престон Звезды мирового детективаПендергаст #18 Специальный агент Алоизий Пендергаст вынужден согласиться с требованиями нового руководства нью-йоркского отделения ФБР: теперь он, знаменитый агент-одиночка, должен работать с напарником. Пендергаст и его новый помощник Колдмун направляются в Майами-Бич, где происходит череда немыслимых убийств. Почерк преступника ошеломляет: он вырезает сердца у своих жертв и оставляет их вместе с загадочными письмами на могилах женщин, совершивших самоубийство десять лет назад. Существует ли связь между всеми этими смертями? Что движет кровожадным психопатом? Пытаясь ответить на эти вопросы, Пендергаст и Колдмун даже не подозревают, какие невероятные обстоятельства вскоре откроются в ходе расследования, полностью меняя всю картину преступления и заставляя содрогнуться даже опытных следователей… Впервые на русском! Стихи для мертвецов Douglas Preston Lincoln Child Verses for the Dead © 2018 by Splendide Mendax, Inc. and Lincoln Child © Г. А. Крылов, перевод, 2020 © Издание на русском языке, оформление. ООО «Издательская Группа „Азбука-Аттикус“», 2020 Издательство АЗБУКА® * * * Дуглас Престон посвящает эту книгу Гусси и Джо Станислау 1 Изабелла Герреро, известная своим друзьям и одноклубникам по игре в бридж как Айрис, осторожно прокладывала себе путь через поросшее пальмами кладбище Бейсайд. Над ее головой раскинулось бескрайнее небо цвета бледной лазури. Часы показывали половину восьмого, температура воздуха поднялась до двадцати пяти градусов, и роса, которая все еще держалась на широколистной августиновой траве, насквозь пропитала кожаные сандалии Айрис. В пухлой руке женщина держала сумку от «Фенди», а в другой сжимала поводок, слабо натянутый ее пекинесом Твинклом. Айрис опасливо пробиралась между надгробиями и клумбами: всего три недели назад Грейс Манизетти, нагруженная продуктами, потеряла равновесие, возвращаясь из местного супермаркета «Пабликс», и сломала тазовую кость. Кладбище открылось полчаса назад, и, кроме Айрис, здесь почти никого не было. Ей это нравилось, ведь Майами-Бич с каждым годом становился все более многолюдным. Даже здесь, в Бал-Харбор, на северной оконечности острова, движение на дорогах было более оживленным, чем в перенаселенном Нью-Йорке времен ее детства, проведенного на бульваре Куинс. А когда несколько лет назад построили этот жуткий молл на Девяносто шестой улице, стало еще хуже. Помимо прочего, с юга начали проникать нежелательные элементы с их магазинами шаговой доступности и casa здесь, tienda[1 - Дом, лавочка (исп.).] там. Слава богу, Фрэнсису хватило ума купить кондоминиум на Гранд-Палмс-Атлантик, прямо на берегу Сёрфсайда и в безопасном от посягательств месте. «Фрэнсис…» Айрис уже видела впереди его могилу, надгробие, слегка выбеленное флоридским солнцем, на чистом и аккуратном участке – она позаботилась об этом. Твинкл, знающий, что место их назначения уже неподалеку, прекратил дергать поводок. Ей было за что благодарить Фрэнсиса.\n",
            "Token IDs 1: tensor([   101,    526,  70216,  10191,  10520,    553,  92190,  14149,  25840,\n",
            "           513,  45209,  38445,    524,  47274,  11579,  90472,  29345,  18248,\n",
            "         89353,  59990,  10852,  16027,  92154,  11977,  11347,  11567,    108,\n",
            "         10218,    526,  93973, 102487,  26657,  26891,  87422,    524,  92154,\n",
            "         11977,  11347,  11567,  67766,  10956,  42805,  99366,  10625,    558,\n",
            "           559,  14348,  49455,  23341,  10508,  23190, 108418,  12830,  10593,\n",
            "           118,    550,  87230,  11184,  50684,    529,  18683,  18005,    131,\n",
            "         53243,  11060,    117,    548,  78936,  15065,  35627, 102487,    118,\n",
            "         13713,  99628,    117,  33660,  45680,    558,  10122, 106064,  20298,\n",
            "           119,    524,  92154,  11977,  11347,  11567,    549,  10933,  30994,\n",
            "         99144,    519,  17010,  10746,  11805,  10267,  10122,  76880,  10541,\n",
            "         66973,    543,    521,  16481,  12040,    118, 102773,  11746,    117,\n",
            "         12252,  33779,  14816,  61146,  17213,  36257,  48552,  12861,    560,\n",
            "         13647,  10384,  19021,    119,  11480,  87869,  38494,  63649,  14071,\n",
            "           555,  42171,  10364,  29061,    131,  11060,  96195, 102233,  25471,\n",
            "         10277,  23479,  11456,    560,  20704, 103914,    549,  85854,  36829,\n",
            "         29061,  12064,  17050,    558,  10234,  11347,  17961,  79997,  87431,\n",
            "         10508,  10122,  40075,  16610,  10353,  24828,    117,  98903,  11977,\n",
            "         45813,  15419,  14847,  40124,  11550,  12232,  78999,  12773,  37178,\n",
            "           119,  97846,  33190,  68454,  13233,  93158,  37266,  10191,  16541,\n",
            "         92190,  21357,    136,  85904,    545,  13791,  15920,  10351,    551,\n",
            "         55048,  17254,  10746,  11692,    556,  13700,  42940,  70588,  10364,\n",
            "           136,    524,  86360,  39269,  83415,  15356,  10122,  26651,  75812,\n",
            "           117,    524,  92154,  11977,  11347,  11567,    549,    519,  17010,\n",
            "         10746,  11805,  10267,  21769,  10375,  11429,  44666, 110442,  31738,\n",
            "           117,  10949,  12686,  10375,  32418,  81802,  11194,  13248,  41054,\n",
            "         13081,  90521,  37264,  10332,  10510,  14315,  17601,    543,  26222,\n",
            "           557,  18291, 109558,    117,  29305,  57132,  10385,  39206,  98385,\n",
            "         10227,  38494,  77214,    549,  10234,  47151,  91040,  10956,  50676,\n",
            "         10823,  46769,  10625,  21769,  90281,  10970,  16246,  12019,  21859,\n",
            "           100,  58190,  10122,  64644,    106,    526,  70216,  10191,  10520,\n",
            "           553,  92190,  14149,  25840,  14860,  35119,  16944,  21640,  46744,\n",
            "         10171,  10142,  10105,  16349,    206,  10434,  10155,  46361,  72384,\n",
            "         10253,  13026,  10229,  10686,    117,  13604,    119,  10111,  16944,\n",
            "         21640,    206,    512,    119,    509,    119,    519,  13325,  18359,\n",
            "           117,  70659,    117,  23607,    206,  37904,  27473,  10122,  64644,\n",
            "         29773,    117,    555,  70619,  10241,  20539,    119,  61164,    208,\n",
            "         37904, 102600,  11980,  75719,   1725,  47841,  19590,  10521,    118,\n",
            "           509,  55330,  11191,  10513,    100,    220,    117,  23607,  50309,\n",
            "           509,  31315,  18683,  16859, 105700, 110892,    115,    115,    115,\n",
            "           513,  45209,  38445,    524,  47274,  11579,  10297,  10513,  84322,\n",
            "         41601,  39971,  49745,    512,  19954,  13700,    549,  72501,    526,\n",
            "        101740,  37936,  10227,    122,  19597,  50889,  13519,  10674,    512,\n",
            "         11977,  14348,  14315,    117,  55897,  10385,  28365,  16522,  45803,\n",
            "         15609,  10241,    549,  41543,  53869,  40124,  96250,  10297,  35813,\n",
            "           543, 109300,  22415,  12025,  10949,  99328,  72655,    117,  85854,\n",
            "         18256,  10316,  24751,  12709,  43067,  59422,  10179,  17072,  46906,\n",
            "         12798,  41436,  17969,  32381,  12634,  12118,  10993,  10508,  39365,\n",
            "           510, 104669,  16481,  10746,    119,  82704,  75431,  64371,  11292,\n",
            "           557,  18291,  31229,  81925,  11833,    542,  17488,  10510,  42174,\n",
            "         26346,  39483,  42128,    542,  11851,  85987,  26670,  19692,  11777,\n",
            "           119,    532,  47704,  45899,  87903,  23750,  87595,  10439,  11833,\n",
            "         64608,    117,  30405,  86478,  11429,  92204,  10344,  12500,  10746,\n",
            "         11456,  10960,  55506,  36650,  28680,    117,    549,  28171,  10179,\n",
            "           117,  16510,  13686,  72284,  90139,  61349,  11833,  10122,  32674,\n",
            "         76113,  48639,  69310,  98607,    559,  41410,  10205,    117,  32001,\n",
            "         10510,  15275,  42366,  12709,  80465,  15522,  59781,    102])\n",
            "Attention Mask 1: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Number of 0s in Token IDs 1: 0\n",
            "Number of 0s in Attention Mask 1: 0\n",
            "\n",
            "Original Text 2: Сказка о смерти Мартен С. Снейдер #3 В Берне обнаружен труп женщины с загадочным символом, который убийца вырезал у нее на груди. Однако это не единственная его жертва. Голландский профайлер Мартен С. Снейдер и комиссар БКА Сабина Немез открывают охоту на преступника, но кажется, что убийца всегда на шаг впереди. Между тем молодой специалист в области психологии Ханна приезжает в «Штайнфельз», тюрьму для преступников с психическими отклонениями. Она должна проводить сеансы групповой терапии. Но ее интересует один-единственный заключенный – Пит ван Лун. Когда-то Снейдер упрятал его за решетку. Так и опытные следователи, и начинающий психолог оказались втянуты в дьявольскую игру, в которой не будет победителя. Сказка о смерти Посвящается Хайдемари Спасибо за последние девятнадцать лет. «Наш злейший враг – это мы сами». Пословица Пролог Пятью годами ранее Мартен С. Снейдер стоял на утесе и не отрываясь смотрел на море. Брызги от волн, разбивавшихся о скалы, подлетали так высоко, что он ощущал легкую соленую морось на лице. Утреннее солнце еще пряталось за туманом, но ветер уже начал проделывать первые прорехи в серой массе. В небе над Снейдером пронзительно кричали чайки. Их что-то напугало. Он посмотрел вниз на маленькую пристань, где также располагалась железнодорожная станция острова-тюрьмы Остхеверзанд. По узкой горной дороге, которую он час назад одолел пешком, как раз поднималась машина. Автозак. В нем везли трех заключенных, но Снейдера интересовал только один из них. Он щелчком отбросил окурок в скалы. Несколько секунд пахло марихуаной, а потом в воздухе остался лишь привычный запах морских водорослей, птичьего помета и мидий, облепивших скалы и омываемых пенящимися морскими волнами. Снейдер отошел от скал и спрятался в тени высокого здания, стоящего позади него. В следующий момент подъехал автозак и, хрустя гравием под колесами, остановился у ворот. Из здания исправительного учреждения вышли два сотрудника в униформе. Без огнестрельного оружия, но с тазерами, газовыми баллончиками и дубинками. По их лицам Снейдер понял, что – если потребуется – они без колебаний жестоко изобьют заключенных. Здесь не было туристов, снимающих видео на мобильные телефоны. Дверь автозака открылась – сначала из машины вылезли двое мужчин в униформе, следом за ними трое заключенных в серых комбинезонах. На ногах у них были кандалы, двое держали перед собой закованные в наручники руки. Третий также был в наручниках – правда, руки ему сцепили за спиной. Вот из-за этого мужчины Снейдер и приехал сюда. Он должен был убедиться, что того действительно упрячут – и навсегда – в это специальное заведение: тюрьму строгого режима для преступников с психическими отклонениями. Снейдер сделал шаг вперед, обратился к сотрудникам и указал на Пита ван Луна: – Вам стоит посильнее затянуть ему наручники.\n",
            "Token IDs 2: tensor([   101,    526,  41710,  10521,    555,  21809,    521,  46466,  10928,\n",
            "           526,    119,    526,  17000,  22605,    108,    124,    511,    510,\n",
            "         80369,  10205,  13248,  37235,  10227,  23855,    559,  14360,  11078,\n",
            "         42403,    558,  10234,  11347,  17961,  27819,  51235,  10364,    117,\n",
            "         12968,    560,  13647,  75096,  96195, 102233,  12743,    560,  10375,\n",
            "         10205,  10122,  55895,  29779,    119,  17549,  12999,  10375,  23727,\n",
            "         48310,  10933, 103914,  10179,    119,    512,  17010,  39666,  11386,\n",
            "         56619,  93782,  11977,    521,  46466,  10928,    526,    119,    526,\n",
            "         17000,  22605,    549,  59781,  10508,  48621,  10519,    510, 105700,\n",
            "         55920,  83281,  21124,  14689,  11571,  10332,  10510,  84113,  13714,\n",
            "           555,  42940,  12803,  10122,  38494,  63649,  14071,    117,  11279,\n",
            "         95434,  22692,    117,  10791,    560,  13647,  75096,  41073,  10122,\n",
            "         79703,  10823,    543,  75556,  10191,    119,  61586,  19710,  96917,\n",
            "           558,  97516,    543,  11431,    556,  13700,  42940,  26749,  77820,\n",
            "         10409,  10913,  32934,  47546,    543,    208,    533,  25987,  10267,\n",
            "         42695,  12118,  11571,    220,    117,    559,  10593,  28301,  11805,\n",
            "         10520,  38494,  63649,  17167,    558,    556,  13700,  22710,  72579,\n",
            "         10332,  67455,  27232,  10508,    119,  25428,  53468,  88184,  10277,\n",
            "         94905,  10292,  54874,  17780,  13613,  11079,  70191,    119,  19732,\n",
            "         75431,  59075,  43699,  13713,    118,  70021,  10234, 101032,  11092,\n",
            "           100,    524,  15811,  39621,    520,  16657,    119,  30053,    118,\n",
            "         11663,    526,  17000,  22605,    560,  35415,  27259,  10517,  10933,\n",
            "         10234,    557, 108654,  48038,    119,  20275,    549,  90281,  11194,\n",
            "         16246,  12019,  24306,    117,    549,  27353,  60893,    556,  13700,\n",
            "         42940,  22141,  96061,    543,  32127,  75029,  10292,    543,    545,\n",
            "         15609, 110687,  10851,  15997,  56762,    117,    543,  16209,  10375,\n",
            "         22366,  98652,  24066,    119,    526,  41710,  10521,    555,  21809,\n",
            "         11480,  10513,  84322,  51901,    530,  16481, 109566,  30090,    526,\n",
            "        107528,  29709,  10234,  52419, 109910,  13081,  89495,  12773,    119,\n",
            "           208,  10778,  11148,    548,  20929,  16483,    543,  80424,    100,\n",
            "         12999,  35818,  77489,    220,    119,  11480,  55984,  87667,  35475,\n",
            "         22141,    524,  20177,  10593, 103363,  10191,  30673,    521,  46466,\n",
            "         10928,    526,    119,    526,  17000,  22605, 108804,  29065,  10122,\n",
            "           560,  10696,  13110,    549,  10375,  10332,  84113,  39269,  16541,\n",
            "         11016,  67244,  10122,  27165,    119,    510,  13325,  11571,  14122,\n",
            "         10332,  10439,  10517,  10267,    117,  17257,  98208,  81991,    555,\n",
            "           558,  48225,  10292,    117,  11429,  67033,  10783,  12123,  96195,\n",
            "         45135,  10316,    117,  10791,  11060,    555,  50642,  58843,  94693,\n",
            "         10823,  42688,  26367,  43909,  10593,    553,  97648,  11833,  10122,\n",
            "         75599,    119,    528,  46672,  10928,  26346,  26367,  67345,  72284,\n",
            "         25484,  27259,  20243,  10234,  37298,  14405,  10364,    117,  11279,\n",
            "           543,  71493,  15530,  23137,  12709,  44030,  72060,  37067,  12709,\n",
            "         14348,  22710,    543,  10277,  62685,  97744,  74044,    119,    511,\n",
            "         10375,  18106,  12614,    526,  17000,  22605,  10364,  12709,  10267,\n",
            "         98907,  19619,    551,  11777,  48859,    564,  99189,  10191,    119,\n",
            "         40655,  10791,    118,  11663,  10122,  35280,  75819,  10316,    119,\n",
            "         14699,  10297,  10513, 104722,  67244, 107093,  10122,  50818,  19557,\n",
            "         42688,  10913,  84946,    117,  12252,  11448,    557,  18291,  95208,\n",
            "         20292, 103699,  37544,  25996,    118,    559,  10593,  28301,  15657,\n",
            "           523,  11567,  57760,  32418,  27659,  10746,    119,  11480,  41733,\n",
            "         14397, 104812,  11075,  69948,    117,  30956,  11060,  12562,  37178,\n",
            "         10430,  64724,  10517,    556,  31751,  13393,    117,  10949,  17257,\n",
            "         11429,  93903,  20013,  51169,    119,    509,  94454,  43650,  10510,\n",
            "           119,    511,  17213,    543,  32934,  10783,  83370,  10234, 101032,\n",
            "         10970,    117,  11279,    526,  17000,  22605,  10179,  59075,  35973,\n",
            "         13721,  13713,  10387,  13614,    119,  14699,  16892,  10517,  52150,\n",
            "         10332,  85584,  17969,  13460,  40936,  20060,  11899,    102])\n",
            "Attention Mask 2: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Number of 0s in Token IDs 2: 0\n",
            "Number of 0s in Attention Mask 2: 0\n",
            "\n",
            "Original Text 3: Темная материя Город в Нигде Джейсон Дессен, выдающийся физик, некогда отказался от блестящей научной карьеры и стал обычным преподавателем в колледже. Теперь все его внимание отдано семье – любимым жене и сыну. Они для Джейсона важнее всего. И вдруг – это нелепое похищение… Неизвестный в маске напал на Дессена на улице, под дулом револьвера усадил его в машину, отвез к заброшенному зданию и ввел ему в вену непонятный препарат. Джейсон потерял сознание. А очнувшись, обнаружил себя окруженным массой людей; все они обращались к нему как к старому другу и наперебой поздравляли его с возвращением – и с тем, что его открытие наконец-то сработало. Вот только Дессен не знал никого из этих людей. И уж тем более не ведал, что за открытие совершил… Темная материя © Перевод на русский язык, С.Н. Самуйлов, 2016 © Издание на русском языке, оформление ООО «Издательство Э», 2017 * * * Для тех, кто хочет знать, какой могла быть жизнь в конце непройденной дороги Что быть могло и что случилось, Все сводится к извечному концу. В памяти эхо шагов По коридору, в который мы не свернули, К двери, которую мы не открыли. Т.С. Элиот «Бернт Нортон» Глава 1 Люблю четверговые вечера. Есть в них что-то вневременное. Такая у нас традиция – семейный вечер, только мы втроем. Мой сын Чарли сидит за столом, рисует что-то в альбоме. Ему почти пятнадцать. Вырос за лето на два дюйма и уже почти догнал меня. Я отворачиваюсь от лука, который режу на разделочной доске. – Можно посмотреть? Сын поднимает альбом, показывает горный хребет – нечто инопланетное. – Мне нравится, – говорю я. – Просто так или… – Домашнее задание. Завтра сдавать. – Что ж, трудись, мистер В-Последнюю-Минуту. Довольный и чуточку пьяный, я стою у себя на кухне и даже не подозреваю, что этот сегодняшний вечер – конец всего. Всего, что я знаю, всего, что люблю. Никто не скажет, что скоро все изменится, что тебя лишат всего-всего. Никакой системы предупреждения о приближающейся опасности нет, как нет ни малейшего указания на то, что ты уже стоишь над пропастью. Может быть, именно поэтому трагедия так трагична. Дело не в том, что случается, а в том, как это случается: удар настигает внезапно, когда ты совсем его не ждешь. Ни увернуться, ни собраться уже не успеваешь. Светодиодные светильники отражаются на поверхности вина в бокале, и в глазах начинает пощипывать от лука. На старенькой вертушке в кабинете крутится пластинка Телониуса Монка. Аналоговые записи можно слушать бесконечно – в них есть некая сочность звучания, особенно эти щелчки между треками.\n",
            "Token IDs 3: tensor([   101,  40272,  11548,  63588,  10385,  49830,    543,    522,  10191,\n",
            "         10823,  12265,  43747, 104669,  11579,  52935,  74044,  10267,    117,\n",
            "         96195,  10987,  71084,  93839,    117,  10375,  29476,  10987,  78213,\n",
            "         10332,    542,  62903,  32127,  30305,  60133,  70580,    549,  13462,\n",
            "         13248,  10292,  27819,  38494,  53204,  83181,  25620,    543,  90363,\n",
            "         87469,  10205,    119,  39968,  29633,  10851,  13686,  10933,  38697,\n",
            "         10332,  84634,  25352,    100,    552,  10593,  13647,  80128,  86714,\n",
            "           549,  22025,  10227,    119,  27708,  10520,  43747, 104669,  14614,\n",
            "         12450,  68501,  18275,    119,    517,    543,  83038,  10823,    100,\n",
            "         12999,  10375,  53370,  17117,  10297,  22710,  26692,    100,  21124,\n",
            "         39457,  14149,  11567,  11092,    543,  97744,  14430,  10122,  55354,\n",
            "         10122,  52935,  74044,  10409,  10122,  44977,    117,  11429,  11576,\n",
            "         22089,    557,  42500,  12118,  77977,    560,  69247,  10517,  10933,\n",
            "           543,  51290,  10227,    117,  10332,  14149,  11571,    551,  10234,\n",
            "         85584,  43155,  85880,  10227,    548,  15196,  13564,    549,  60345,\n",
            "         13519,  16929,    543,    543,  43909,  10375,  91925,  13081,  11092,\n",
            "         38494,  41895,    119,  43747, 104669,  11579,  10297,  15469,  29065,\n",
            "         10956, 101495,    119,    509,    555,  28056,  65495,    117,  13248,\n",
            "         37235,  10227,  29189,  17900,  40936,  14360,  23855,  11692,  97744,\n",
            "         98617,  10384,  17358,    132,  13686,  14274,  13248,  11079,  58843,\n",
            "         19935,    551,  61208,  10949,    551,  15888,  95605,  11805,  70723,\n",
            "           549,  10122,  29633,  59373,  11292,  10297,  62594,  41410,  48499,\n",
            "         10933,    558,  10439, 105283,  50087,  10241,    100,    549,    558,\n",
            "         19710,    117,  10791,  10933,  60427,  12686, 102310,    118,  11663,\n",
            "           558,  79050,  10316,    119,  12624,  10351,  13721,  52935,  74044,\n",
            "         10267,  10375,    548,  25829,  19544,  18632,  10387,  23459,  17358,\n",
            "           119,    517,    560,  12025,  19710,  13106,  10375,    543,  63253,\n",
            "         10517,    117,  10791,  10234,  60427,  12686,  75083,    100,  40272,\n",
            "         11548,  63588,  10385,    206,  54247,  42500,  10746,  10122,  37619,\n",
            "         29757,    117,    526,    119,    522,    119,  51640, 110247,  18359,\n",
            "           117,  10255,    206,  37904,  27473,  10122,  64644,  29773,    117,\n",
            "           555,  70619,  10241,  20539,  61164,    208,  50309,    538,    220,\n",
            "           117,  10302,    115,    115,    115,  15668,  32323,    117,  35261,\n",
            "           562, 110732,    548,  71422,    117,  78351,  51734,  17631,  27264,\n",
            "           543,  18895,  10375, 104082,  74346,  46336,  33949,  85904,  17631,\n",
            "         78664,    549,  10791,  52399,  63755,  16353,    117,  28572,  37629,\n",
            "         50975,  22692,    551,  10387,  14149,  49146,  67796,    119,    511,\n",
            "         50447,    570,  42940,  79703,  47204,  11480,  80062,  22415,  32579,\n",
            "           117,    543,  12968,  35818,  10375,  25544,  55399,  30102,    117,\n",
            "           519,  14919,  11777,    117,  30956,  35818,  10375,  10332,  89038,\n",
            "         10191,    119,    527,    119,    526,    119,  63891,  37754,    208,\n",
            "           510,  80369,  10351,  19732,  54555,  10267,    220,  70509,    122,\n",
            "           520,  10593,  61394,  10593,  14816,  35795,  54841,  30165,  45721,\n",
            "         11079,    119,    514,  12737,    543,  13614,  10791,    118,  11663,\n",
            "        103072,  87784,  10205,    119,  35150,  10385,    560,  32001,    559,\n",
            "         76561,  12942,    100,  67338,  11092,  45721,  10519,    117,  13721,\n",
            "         35818,    543,  62735,  12579,    119,    521,  11292,  22025,    532,\n",
            "        103480,  12662,  96655,  10234, 108804,  22089,    117,    557,  19120,\n",
            "         43699,  10791,    118,  11663,    543,  20488,  10205,    119,    514,\n",
            "         11805,  21797,    556,  13081,  89495,    119,  33703,  44181,  10234,\n",
            "        108276,  10122,  12500,    545,  10593,  88215,    549,  15530,  21797,\n",
            "         10344,  81080,  57132,    119,    540,  10332,  59788,  40181, 103270,\n",
            "         11833,  10332,    552,  37087,    117,  12968,  44567,  10227,  10122,\n",
            "         17257,  44030,  76035,  10344,  14430,    119,    100,    521,  10316,\n",
            "         24751,  10297,  10513, 104722, 101312,    136,  56794,  11429,  97582,\n",
            "         11613,  20488,    117,  45899,  46702, 104812,  11092,    562,  14348,\n",
            "         67218,    100,  10375,  11746,  10752,  27796,  58056,    102])\n",
            "Attention Mask 3: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Number of 0s in Token IDs 3: 0\n",
            "Number of 0s in Attention Mask 3: 0\n",
            "\n",
            "Original Text 4: Позже Темная башня (АСТ) Джейми Конклин, живущий с матерью в Нью-Йорке, хочет быть всего лишь обычным подростком… но у него есть весьма необычный дар. Дар, который его мама настоятельно просит скрывать от других. Джейми умеет разговаривать с теми, кого уже нет на этом свете, а значит, ему доступны секреты, ушедшие с покойным в могилу. Однако обладание этим даром может стоить Джейми слишком дорого. В чем он скоро и убеждается, когда мамина подруга, детектив Лиз Даттон, просит его помочь разгадать последнее послание серийного подрывника. А на кону – десятки, сотни невинных жизней… Позже Крису Лоттсу Завтрашних дней не так много. Майкл Лэндон Серия «Темная башня» Stephen King LATER Перевод с английского Т. Покидаевой Фото автора на обложке: Shane Leonard Печатается с разрешения автора и литературных агентств The Lotts Agency и Andrew Nurnberg. © Stephen King, 2021 © Перевод. Т. Покидаева, 2021 © Издание на русском языке AST Publishers, 2021 Я не люблю начинать с извинений – возможно, даже есть правило, запрещающее подобный прием, вроде правила, что предложение не должно оканчиваться предлогом, – но, перечитав первые тридцать страниц, я подумал, что извиниться все-таки надо. Извиниться за частое употребление слова из пяти букв, начинающегося на «п». Нет, это не то, о чем вы подумали. Хотя то слово, как и много других нехороших слов, перенятых у мамы, я тоже знал с юных лет (в чем вам еще предстоит убедиться). Я имею в виду слово «позже» в таких сочетаниях, как «позже я выяснил» или «только позже я понял». Да, оно повторяется слишком часто, но я не знаю, как построить рассказ по-другому, потому что моя история начинается в те времена, когда я еще верил в Санта-Клауса и зубную фею (хотя даже в шесть лет у меня уже были сомнения). Сейчас мне двадцать два, и «позже» вроде как наступило, да? Наверное, когда мне исполнится сорок – при условии, что я доживу до такого возраста, – я вспомню все, что, как мне представлялось, понимал в двадцать два года, и приду к выводу, что очень многого не понимал. Всегда есть какое-то «позже», теперь я это знаю. По крайней мере, пока мы не умрем. А потом, видимо, наступает все, что было раньше. Меня зовут Джейми Конклин, и когда-то давным-давно я нарисовал индейку ко Дню благодарения. Мне казалось, что она офигенная. Позже – причем ненамного позже – выяснилось, что она откровенно фиговая. Иногда правда бывает паршивой. Мне кажется, это будет история в жанре ужасов. Смотрите сами. 1 Я возвращался домой из школы вместе с мамой.\n",
            "Token IDs 4: tensor([   101,  48679,  40272,  11548,  40139,  12751,    113, 102102,    114,\n",
            "         43747,  11742,  10508,    519,  11579,  56200,  10267,    117,  78736,\n",
            "         64098,    558,  97744,  15469,  27025,    543,  19689,    118,  94364,\n",
            "           117,    562, 110732,  17631,  18275,  20489,  13248,  10292,  27819,\n",
            "         11429,  44181,  71501,  10241,    100,  11279,    560,  13981,  17622,\n",
            "         60391,  10375,  94434,  25711,  11820,    119,  29037,    117,  12968,\n",
            "         10933,  97744,  10993,  32001,  10752,  13081,  49161,  12709, 109287,\n",
            "           558,  10510,  84113,  11258,  10332,  15597,    119,  43747,  11742,\n",
            "         10508,  39510,  38049,  10351,  17257,  47204,  30090,  27013,    558,\n",
            "         79746,    117,  86701,  15530,  31428,  10122,  14551,  40363,  10205,\n",
            "           117,    541,  59737,  10351,    117,  16929,  76626,  11307,  10277,\n",
            "         91807,  10292,    117,    560,  13391,  10746,  23352,    558,  10297,\n",
            "         14397,  11692,    543,  40075,  13460,  10227,    119,  17549,  58742,\n",
            "         36069,  13541,  37266,  11820,  10364,  16087,  75363,  10851,  43747,\n",
            "         11742,  10508,  68923,  91376,  10316,    119,    511,  18658,  11060,\n",
            "         46068,    549,    560,  18106, 101584,  10625,    117,  15283,  97744,\n",
            "         61747,  11429,  75624,  10179,    117,  89353,  59990,  10541,  41655,\n",
            "         11571,  30417,  98869,  10267,    117,  12709, 109287,  10933,  96358,\n",
            "         10316,  40697,  17257,  11347,  57548, 107366,  10297,  91008,  12686,\n",
            "         10277,  38864,  11050,  11429,  77851,  14071,    119,    509,  10122,\n",
            "         33023,  10227,    100,  11323,  83125,  10648,    117,  10956,  38842,\n",
            "         10375,  49048,  10970,    547,  39457,  17000,    100,  48679,  93275,\n",
            "         10227,  88909,  10351, 107195,  10227,  11712,  94454,  11079,  93825,\n",
            "         29835,  10375,  12123,  16318,    119,  55609,    520,  16893,  42999,\n",
            "         70802,    208,  40272,  11548,  40139,  12751,    220,  13866,  11515,\n",
            "         29079,  99552,  54247,  42500,  10746,    558,  94803,    527,    119,\n",
            "         11480,  10648,  10987,  63619,    529,  19517,  56740,  10122,  58742,\n",
            "         10316,  12025,  11557,    131,  40429,  20318,    524, 106173,  10367,\n",
            "         14317,    558,  17257,  14348,  27711,  56740,    549,  99197,  14961,\n",
            "         44066,  10970, 102487,  19021,  10117,  34837,  10806,  21887,    549,\n",
            "         13999,  29851,  33199,    119,    206,  13866,  11515,    117,  67267,\n",
            "           206,  54247,  42500,  10746,    119,    527,    119,  11480,  10648,\n",
            "         10987,  17759,    117,  67267,    206,  37904,  27473,  10122,  64644,\n",
            "         29773,  17421,  11090,  22764,    117,  67267,    540,  10375,    552,\n",
            "         10593,  61394,  10593,  27353,  18235,    558,  10387,  69913,  11532,\n",
            "           100,  44504,    117,  21769,  17622,  29349,    117,  10234,  35415,\n",
            "         10205,  15545,  54912,  11429,  33276,  11092,  10913,  12579,    117,\n",
            "           543,  70242,  10205,  53805,    117,  10791,  87803,  10375,  80323,\n",
            "         40936,  11240,  40181,  55125,  23807,  54270,  10241,    117,    100,\n",
            "         11279,    117,  61381,  94218,  36829,  37067,  13251,  93283,  41021,\n",
            "         12181,    117,    572,  11429,  34761,  10517,    117,  10791,  10387,\n",
            "         49048,  56051,  13686,    118, 103835,  12614,  10316,    119,  19597,\n",
            "         49048,  56051,  10234,  18685,  10205,    560,  53204,  46672,  59373,\n",
            "         20539,  25217,  10387,  55506,  18261,  10510,  10541,    117,  27353,\n",
            "        103270,  36049,  10625,  10122,    208,    556,    220,    119,  21124,\n",
            "         10351,    117,  12999,  10375,  11663,    117,    555,  18658,  96195,\n",
            "         11429,  34761,  10783,    119,  57090,  11663,  42638,    117,  10949,\n",
            "           549,  16318,  15597,  10375,  42940,  14315,  15419,  45498,    117,\n",
            "         61381,  10928,  13081,  12861,    560,  97744,  15657,    117,    572,\n",
            "         62416,    548,  25829,    558,    571,  10970,  12773,    113,    543,\n",
            "         18658,  12450,  10241,  72284,  23807,  41054,  15811,    560, 107813,\n",
            "         56051,    114,    119,    540,  24504,  10593,    543,  50548,  42638,\n",
            "           208,  30532,    220,    543,  19420,  10956,  69022, 104985,    117,\n",
            "         10949,    208,  30532,    572,  96195,  89887,  54115,    220,  10880,\n",
            "           208,  13721,  30532,    572,  10297,  47514,    220,    119,  30417,\n",
            "           117,  40182,  30148,  18256,  43128,  68923,  18685,    117,  11279,\n",
            "           572,  10375,    548,  10409,  10593,    117,  10949,    102])\n",
            "Attention Mask 4: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Number of 0s in Token IDs 4: 0\n",
            "Number of 0s in Attention Mask 4: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO3MaaVkuI-c",
        "outputId": "51287b55-91df-4120-88dc-ea0a44673392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 80-10-10 train-validation-test split\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.7 * len(dataset))\n",
        "print(len(dataset))\n",
        "val_size = int(0.1* len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"{train_size} training samples\")\n",
        "print(f\"{val_size} validation samples\")\n",
        "print(f\"{test_size} test samples\")\n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7334\n",
            "5133 training samples\n",
            "733 validation samples\n",
            "1468 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiHoD0KoNpZq"
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# For test the order doesn't matter, so we'll just read them sequentially.\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = SequentialSampler(test_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print DataLoader details\n",
        "def print_dataloader_details(dataloader, name):\n",
        "    print(f\"Details of {name}:\")\n",
        "    # Print number of batches\n",
        "    print(f\"Number of batches: {len(dataloader)}\")\n",
        "    # Print batch size\n",
        "    batch_size = dataloader.batch_size\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "\n",
        "    # Print details of the first batch\n",
        "    first_batch = next(iter(dataloader))\n",
        "    print(\"\\nDetails of the first batch:\")\n",
        "    print(f\"Input IDs shape: {first_batch[0].shape}\")\n",
        "    print(f\"Attention Masks shape: {first_batch[1].shape}\")\n",
        "    print(f\"Labels shape: {first_batch[2].shape}\")\n",
        "\n",
        "# Print details for training, validation, and test dataloaders\n",
        "print_dataloader_details(train_dataloader, \"Training DataLoader\")\n",
        "print_dataloader_details(validation_dataloader, \"Validation DataLoader\")\n",
        "print_dataloader_details(test_dataloader, \"Test DataLoader\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGzH0sOrV9CQ",
        "outputId": "426dd000-b51e-4b68-fa85-fa9db69f2887"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Details of Training DataLoader:\n",
            "Number of batches: 322\n",
            "Batch size: 16\n",
            "\n",
            "Details of the first batch:\n",
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Masks shape: torch.Size([16, 512])\n",
            "Labels shape: torch.Size([16])\n",
            "Details of Validation DataLoader:\n",
            "Number of batches: 46\n",
            "Batch size: 16\n",
            "\n",
            "Details of the first batch:\n",
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Masks shape: torch.Size([16, 512])\n",
            "Labels shape: torch.Size([16])\n",
            "Details of Test DataLoader:\n",
            "Number of batches: 92\n",
            "Batch size: 16\n",
            "\n",
            "Details of the first batch:\n",
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Masks shape: torch.Size([16, 512])\n",
            "Labels shape: torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1IY9cwiAUCZ"
      },
      "source": [
        "## Create and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWfvlMlBg-3_",
        "outputId": "e837d6bd-a043-40dc-f210-cedc87112c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "\n",
        "\n",
        "# Load pretrained model for sequence classification\n",
        "print(f\"Loading {model_name} model...\")\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "\n",
        "# Set the number of labels (number of classes)\n",
        "config.num_labels = len(label_names)  # Ensure this is set to 11 for 0-10 labels\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading bert-base-multilingual-cased model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIBG_g36utJA",
        "outputId": "674529cc-48ab-43c7-94f2-6e0445b1ae81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                          (11, 768)\n",
            "classifier.bias                                                (11,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzojbxacu1ee"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5, у меня 1e-3\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFeBj0EhyGlx"
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
        "epochs = 16\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "epochs=3"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs5ImW58hZ4-"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbwgopNUhm-M"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub1-0NFChoc6",
        "outputId": "884335db-3dac-446d-fb80-fe4fb671c592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set the seed value for reproducibility\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Example model initialization (replace with your model)\n",
        "# model = YourModelClass().to(device)\n",
        "\n",
        "# Example dataloaders (replace with your dataloaders)\n",
        "# train_dataloader = DataLoader(...)\n",
        "# validation_dataloader = DataLoader(...)\n",
        "\n",
        "# Example optimizer and scheduler (replace with your optimizer and scheduler)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "def format_time(seconds):\n",
        "    \"\"\"Converts a time in seconds into a string of format h:mm:ss\"\"\"\n",
        "    return str(time.strftime(\"%H:%M:%S\", time.gmtime(seconds)))\n",
        "\n",
        "def train():\n",
        "    \"\"\"Function to train the model\"\"\"\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 40 == 0 and step != 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(f'  Batch {step:>5,} of {len(train_dataloader):>5,}. Elapsed: {elapsed}.')\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        # Check the outputs to handle the unpacking\n",
        "        if isinstance(outputs, tuple):\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "        else:\n",
        "            # Handle cases where the model might return a single output\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    return avg_train_loss\n",
        "\n",
        "def evaluate():\n",
        "    \"\"\"Function to evaluate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        if isinstance(outputs, tuple):\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "        else:\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.cpu().numpy()\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    return avg_val_loss, avg_val_accuracy\n",
        "\n",
        "# Training loop\n",
        "epochs = epochs  # Set your number of epochs\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "    print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
        "    print(\"Training...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    avg_train_loss = train()\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
        "    print(f\"  Training epoch took: {training_time}\")\n",
        "\n",
        "    print(\"\\nRunning Validation...\")\n",
        "    t0 = time.time()\n",
        "    avg_val_loss, avg_val_accuracy = evaluate()\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(f\"  Validation Loss: {avg_val_loss:.2f}\")\n",
        "    print(f\"  Validation Accuracy: {avg_val_accuracy:.2f}\")\n",
        "    print(f\"  Validation took: {validation_time}\")\n",
        "\n",
        "    training_stats.append({\n",
        "        'epoch': epoch_i + 1,\n",
        "        'Training Loss': avg_train_loss,\n",
        "        'Valid. Loss': avg_val_loss,\n",
        "        'Valid. Accur.': avg_val_accuracy,\n",
        "        'Training Time': training_time,\n",
        "        'Validation Time': validation_time\n",
        "    })\n",
        "\n",
        "print(f\"\\nTraining complete! Total training took {format_time(time.time() - total_t0)} (h:mm:ss)\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of   321. Elapsed: 00:00:26.\n",
            "  Batch    80 of   321. Elapsed: 00:00:54.\n",
            "  Batch   120 of   321. Elapsed: 00:01:22.\n",
            "  Batch   160 of   321. Elapsed: 00:01:50.\n",
            "  Batch   200 of   321. Elapsed: 00:02:18.\n",
            "  Batch   240 of   321. Elapsed: 00:02:47.\n",
            "  Batch   280 of   321. Elapsed: 00:03:15.\n",
            "  Batch   320 of   321. Elapsed: 00:03:42.\n",
            "  Average training loss: 1.76\n",
            "  Training epoch took: 00:03:43\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.32\n",
            "  Validation Accuracy: 0.57\n",
            "  Validation took: 00:00:11\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of   321. Elapsed: 00:00:27.\n",
            "  Batch    80 of   321. Elapsed: 00:00:55.\n",
            "  Batch   120 of   321. Elapsed: 00:01:23.\n",
            "  Batch   160 of   321. Elapsed: 00:01:51.\n",
            "  Batch   200 of   321. Elapsed: 00:02:19.\n",
            "  Batch   240 of   321. Elapsed: 00:02:47.\n",
            "  Batch   280 of   321. Elapsed: 00:03:15.\n",
            "  Batch   320 of   321. Elapsed: 00:03:43.\n",
            "  Average training loss: 1.21\n",
            "  Training epoch took: 00:03:44\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.18\n",
            "  Validation Accuracy: 0.59\n",
            "  Validation took: 00:00:11\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of   321. Elapsed: 00:00:27.\n",
            "  Batch    80 of   321. Elapsed: 00:00:55.\n",
            "  Batch   120 of   321. Elapsed: 00:01:23.\n",
            "  Batch   160 of   321. Elapsed: 00:01:51.\n",
            "  Batch   200 of   321. Elapsed: 00:02:19.\n",
            "  Batch   240 of   321. Elapsed: 00:02:47.\n",
            "  Batch   280 of   321. Elapsed: 00:03:15.\n",
            "  Batch   320 of   321. Elapsed: 00:03:43.\n",
            "  Average training loss: 0.99\n",
            "  Training epoch took: 00:03:44\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.19\n",
            "  Validation Accuracy: 0.60\n",
            "  Validation took: 00:00:11\n",
            "\n",
            "Training complete! Total training took 00:11:45 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxik8IiPhvXC",
        "outputId": "0a527cc1-5ec9-41da-aecf-012d477d6ecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Set float display precision to two decimal places.\n",
        "pd.set_option('display.float_format', lambda x: f'{x:.2f}')\n",
        "\n",
        "# Create a DataFrame from your training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "print(df_stats)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
            "epoch                                                                         \n",
            "1               1.76         1.32           0.57      00:03:43        00:00:11\n",
            "2               1.21         1.18           0.59      00:03:44        00:00:11\n",
            "3               0.99         1.19           0.60      00:03:44        00:00:11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2G-EegN85iC",
        "outputId": "ffc72f29-ed9d-48db-c760-6abc8225ed82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot styling\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plotting\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Labeling\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks(ticks=range(len(df_stats.index)), labels=df_stats.index)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWmaN_QFZKvd"
      },
      "source": [
        "## Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhhTNEe2ZQM-",
        "outputId": "6db7d76b-cc34-41a5-c37c-2addab5b6ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print(\"Predicting labels ...\")\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(input_ids=b_input_ids,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(logits)\n",
        "  true_labels.extend(label_ids)\n",
        "\n",
        "print(f\"Predicted {len(predictions)} samples\")"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels ...\n",
            "Predicted 1468 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htdXUiYk7fyB",
        "outputId": "b6dd776e-5111-4e8b-ca55-67fdd26ba651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = np.argmax(predictions, axis=1)\n",
        "print(f\"Test set accuracy: {accuracy_score(true_labels, predictions)}\")\n",
        "print(f\"Test set Matthews correlation coefficient: {matthews_corrcoef(true_labels, predictions)}\")"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy: 0.5783378746594006\n",
            "Test set Matthews correlation coefficient: 0.5228691533710695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Prediction on test set\n",
        "print(\"Predicting labels ...\")\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions, true_labels, all_logits = [], [], []\n",
        "\n",
        "# Predict\n",
        "for batch in test_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    test_dataloader\n",
        "    # Store logits and true labels\n",
        "    all_logits.extend(logits)\n",
        "    true_labels.extend(label_ids)\n",
        "\n",
        "# Convert logits to class labels\n",
        "predictions = np.argmax(all_logits, axis=1)\n",
        "true_labels = np.array(true_labels).flatten()\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_labels, predictions, output_dict=True, zero_division=0)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(true_labels, predictions, zero_division=0))\n",
        "\n",
        "# Save the classification report to a CSV file\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "report_df.to_csv('classification_report.csv', index=True)\n",
        "\n",
        "print(\"Classification report saved to 'classification_report.csv'\")\n",
        "\n",
        "# Create a DataFrame for detailed predictions after argmax\n",
        "detailed_predictions_df = pd.DataFrame({\n",
        "    'True Label': true_labels,\n",
        "    'Predicted Label': predictions,\n",
        "    'Logits': [logit.tolist() for logit in all_logits]  # Convert logits to list for CSV storage\n",
        "})\n",
        "\n",
        "# Save detailed predictions to a CSV file\n",
        "detailed_predictions_df.to_csv('detailed_predictions.csv', index=False)\n",
        "\n",
        "print(\"Detailed predictions saved to 'detailed_predictions.csv'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJWhjQU_xtH1",
        "outputId": "990d8a0f-55c1-46ff-ed8c-87980724b9f9"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.53      0.43       109\n",
            "           1       0.33      0.04      0.07        24\n",
            "           2       0.68      0.58      0.63       194\n",
            "           3       0.52      0.63      0.57       207\n",
            "           4       0.59      0.54      0.56       211\n",
            "           5       0.00      0.00      0.00        36\n",
            "           6       0.65      0.75      0.69       204\n",
            "           7       0.74      0.59      0.66        96\n",
            "           8       0.50      0.39      0.44        61\n",
            "           9       0.78      0.78      0.78       153\n",
            "          10       0.44      0.45      0.45       173\n",
            "\n",
            "    accuracy                           0.58      1468\n",
            "   macro avg       0.51      0.48      0.48      1468\n",
            "weighted avg       0.57      0.58      0.57      1468\n",
            "\n",
            "Classification report saved to 'classification_report.csv'\n",
            "Detailed predictions saved to 'detailed_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training predictions and labels\n",
        "train_predictions = []\n",
        "train_true_labels = []\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "\n",
        "    train_predictions.extend(predictions)\n",
        "    train_true_labels.extend(label_ids)\n",
        "\n",
        "# Generate training classification report\n",
        "train_report = classification_report(train_true_labels, train_predictions, output_dict=True, zero_division=0)\n",
        "print(\"Training classification report:\\n\", train_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYOzRwNY0pyH",
        "outputId": "6c4a6b59-3aeb-4aee-f18e-7955b81494e6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classification report:\n",
            " {'0': {'precision': 0.5, 'recall': 0.020642201834862386, 'f1-score': 0.039647577092511016, 'support': 436.0}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 84.0}, '2': {'precision': 0.3991060025542784, 'recall': 0.9018759018759018, 'f1-score': 0.5533421868083223, 'support': 693.0}, '3': {'precision': 0.6673387096774194, 'recall': 0.49774436090225566, 'f1-score': 0.570198105081826, 'support': 665.0}, '4': {'precision': 0.6181575433911882, 'recall': 0.6739446870451238, 'f1-score': 0.6448467966573816, 'support': 687.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 154.0}, '6': {'precision': 0.7221238938053097, 'recall': 0.5770862800565771, 'f1-score': 0.6415094339622641, 'support': 707.0}, '7': {'precision': 0.6351351351351351, 'recall': 0.7366771159874608, 'f1-score': 0.6821480406386067, 'support': 319.0}, '8': {'precision': 0.45933014354066987, 'recall': 0.463768115942029, 'f1-score': 0.46153846153846156, 'support': 207.0}, '9': {'precision': 0.77088948787062, 'recall': 0.89937106918239, 'f1-score': 0.8301886792452831, 'support': 636.0}, '10': {'precision': 0.49645390070921985, 'recall': 0.38181818181818183, 'f1-score': 0.4316546762589928, 'support': 550.0}, 'accuracy': 0.573958738808875, 'macro avg': {'precision': 0.4789577106076219, 'recall': 0.46844799224043476, 'f1-score': 0.44137035975305905, 'support': 5138.0}, 'weighted avg': {'precision': 0.5711563515828165, 'recall': 0.573958738808875, 'f1-score': 0.5362095944938656, 'support': 5138.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5EStuaZBGLk"
      },
      "source": [
        "## Save model to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZIqwQvuBKFZ",
        "outputId": "ff57e021-6e37-4c05-8cfe-7362bb5c56fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = f\"./{model_name}/\"\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"Saving model to {output_dir}\")\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./DeepPavlov/rubert-base-cased/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./DeepPavlov/rubert-base-cased/tokenizer_config.json',\n",
              " './DeepPavlov/rubert-base-cased/special_tokens_map.json',\n",
              " './DeepPavlov/rubert-base-cased/vocab.txt',\n",
              " './DeepPavlov/rubert-base-cased/added_tokens.json',\n",
              " './DeepPavlov/rubert-base-cased/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le22WIOxhSaj",
        "outputId": "1b91b045-6845-4ab1-993c-dfe2f1cd767f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaXz2CrQhVyo"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "target_dir = f\"\\\"./drive/My Drive/NLP/BERT CLF 10kGNAD/\\\"\"\n",
        "!cp -r $output_dir $target_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tXFWVdxh7Zd"
      },
      "source": [
        "## Load Model from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94-4pMG-h_G_",
        "outputId": "85be8835-6ea6-4b37-ff12-9ed14c343690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "output_dir = f\"./content/drive/MyDrive/Colab Notebooks/{model_name}/\"\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Incorrect path_or_model_id: './content/drive/MyDrive/Colab Notebooks/DeepPavlov/rubert-base-cased/'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './content/drive/MyDrive/Colab Notebooks/DeepPavlov/rubert-base-cased/'. Use `repo_type` argument if needed.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-20cd8abc0eee>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load a trained model and vocabulary that you have fine-tuned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    486\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHFValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;34mf\"Incorrect path_or_model_id: '{path_or_repo_id}'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         ) from e\n",
            "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: './content/drive/MyDrive/Colab Notebooks/DeepPavlov/rubert-base-cased/'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT525N9VbR8n"
      },
      "source": [
        "## Predict on some sample text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI_uBpaWxZaY"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esq849IYbVj2"
      },
      "source": [
        "texts = [\"Heldt hätte kein Problem damit, wenn es in zwei Wochen in der Bundesliga wieder losgehen würde. „Wir lernen gerade alle, Kompromisse einzugehen, an die wir vor Wochen noch nicht gedacht haben.“ Natürlich seien zehn bis 14 Tage richtiges Mannschaftstraining sinnvoll. „Aber vielleicht kriegen wir diese Zeit nicht. Und dann machen wir es so“, ergänzte der langjährige Manager. Köln-Profi Birger Verstraete hält die Maßnahmen nach den drei positiven Corona-Tests derweil für leichtsinnig. „Wir sollten vorerst nicht unter Quarantäne gestellt werden, und das ist ein bisschen bizarr“, sagte der belgische Mittelfeldspieler dem TV-Sender „VTM“. Beim 1. FC Köln waren zwei Spieler und ein Betreuer positiv auf das Coronavirus getestet worden. „Der Physiotherapeut ist der Mann, der mich und andere Spieler wochenlang behandelt hat. Und mit einem der beiden fraglichen Spieler habe ich am Donnerstag im Fitnessstudio ein Duo gebildet“, sagte Verstraete in dem Interview, über das „Het Laatste Nieuws berichtete.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2PSbpD9bcqa"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in texts:\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                          text,\n",
        "                          add_special_tokens = True,\n",
        "                          max_length = 64,\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                          return_tensors = 'pt')\n",
        "\n",
        "  # Add the encoded sentence to the list.\n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  # And its attention mask (simply differentiates padding from non-padding).\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBv57F46cKST"
      },
      "source": [
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "last_layer_attentions = []\n",
        "\n",
        "# Move input ids and attention masks to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_masks = attention_masks.to(device)\n",
        "\n",
        "for i in range(len(input_ids)):\n",
        "\n",
        "  ids = input_ids[i].unsqueeze(0)\n",
        "  masks = attention_masks[i].unsqueeze(0)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(input_ids=ids,\n",
        "                      attention_mask=masks)\n",
        "\n",
        "  # Get logits and compute softmax\n",
        "  logits = outputs[0]\n",
        "  logits = torch.softmax(logits,dim=1)\n",
        "  last_layer_attention = outputs[1][-1]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  last_layer_attention = last_layer_attention.detach().cpu().numpy()\n",
        "\n",
        "  last_layer_attentions.append(last_layer_attention)\n",
        "  predictions.append(logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8t_Ygply0X3",
        "outputId": "358e0eba-eda2-4a6f-cac5-58bce5169187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "probs = predictions[0][0]\n",
        "print(\"text:\", texts[0])\n",
        "print(\"predictions:\", probs)\n",
        "pred_idx = np.argmax(probs)\n",
        "print(f\"Prediction: {label_names[pred_idx]} ({probs[pred_idx]:.2f})\", )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Heldt hätte kein Problem damit, wenn es in zwei Wochen in der Bundesliga wieder losgehen würde. „Wir lernen gerade alle, Kompromisse einzugehen, an die wir vor Wochen noch nicht gedacht haben.“ Natürlich seien zehn bis 14 Tage richtiges Mannschaftstraining sinnvoll. „Aber vielleicht kriegen wir diese Zeit nicht. Und dann machen wir es so“, ergänzte der langjährige Manager. Köln-Profi Birger Verstraete hält die Maßnahmen nach den drei positiven Corona-Tests derweil für leichtsinnig. „Wir sollten vorerst nicht unter Quarantäne gestellt werden, und das ist ein bisschen bizarr“, sagte der belgische Mittelfeldspieler dem TV-Sender „VTM“. Beim 1. FC Köln waren zwei Spieler und ein Betreuer positiv auf das Coronavirus getestet worden. „Der Physiotherapeut ist der Mann, der mich und andere Spieler wochenlang behandelt hat. Und mit einem der beiden fraglichen Spieler habe ich am Donnerstag im Fitnessstudio ein Duo gebildet“, sagte Verstraete in dem Interview, über das „Het Laatste Nieuws berichtete.\n",
            "predictions: [1.0679949e-03 8.8444026e-04 3.8669645e-03 1.7328591e-03 7.7026529e-04\n",
            " 9.8628575e-01 9.4877667e-04 3.0755729e-03 1.3673912e-03]\n",
            "Prediction: Sport (0.99)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi9mhLaryMNS",
        "outputId": "da989ec5-5025-4677-8d85-76995910a966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "fig = plt.figure(tight_layout=True)\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "y_pos = np.arange(len(label_names))\n",
        "confidences = [probs[i] for i in range(len(label_names))]\n",
        "\n",
        "ax.barh(y_pos, confidences, align='center')\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels(label_names)\n",
        "ax.invert_yaxis()  # labels read top-to-bottom\n",
        "ax.set_xlabel('Confidence')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofcRyMHTxh_f"
      },
      "source": [
        "### Visualize Attentions\n",
        "\n",
        "For each token, visualize the average over all 12 heads of the last layer's attention to the special character [CLS]. The darker the background of the token, the higher its attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3r6jQpFKWWb"
      },
      "source": [
        "lla = last_layer_attentions[0][0][:,0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDiU0fPDTgkF"
      },
      "source": [
        "def avg_token_attentions(last_layer_attentions):\n",
        "  return last_layer_attentions.mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iYtEu5vhJPM"
      },
      "source": [
        "avg_token_atts = avg_token_attentions(lla)\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpp6Q3EHoovo"
      },
      "source": [
        "def handle_special_token_attentions(tokens, avg_token_atts):\n",
        "  new_tokens = []\n",
        "  new_avg_token_atts = []\n",
        "  for i in range(len(tokens)):\n",
        "    if tokens[i].startswith(\"[\") or tokens[i].startswith(\"##\"):\n",
        "      continue\n",
        "    if i < tokenizer.max_len - 1 and tokens[i+1].startswith(\"##\"):\n",
        "      merged_tokens = tokens[i] + tokens[i+1][2:]\n",
        "      atts = [avg_token_atts[i], avg_token_atts[i+1]]\n",
        "      i += 1\n",
        "      while i < tokenizer.max_len - 1 and tokens[i+1].startswith(\"##\"):\n",
        "        merged_tokens += tokens[i+1][2:]\n",
        "        atts.append(avg_token_atts[i+1])\n",
        "        i += 1\n",
        "      new_tokens.append(merged_tokens)\n",
        "      new_avg_token_atts.append(sum(atts)/len(atts))\n",
        "    elif i < tokenizer.max_len - 1:\n",
        "      new_tokens.append(tokens[i])\n",
        "      new_avg_token_atts.append(avg_token_atts[i])\n",
        "  new_avg_token_atts = new_avg_token_atts / sum(new_avg_token_atts)\n",
        "  return new_tokens, new_avg_token_atts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC7Y8NcVq3w3"
      },
      "source": [
        "tokens, avg_token_atts = handle_special_token_attentions(tokens, avg_token_atts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrCl0RbXmu2W",
        "outputId": "c616553f-624b-4e16-9c6f-019795991521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "for token, att in zip(tokens, avg_token_atts):\n",
        "  print(token, att)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Heldt 0.05963272150050977\n",
            "hätte 0.05842705044356964\n",
            "kein 0.015847744346937087\n",
            "Problem 0.01636351010862091\n",
            "damit 0.013772409461545421\n",
            ", 0.036807565532129716\n",
            "wenn 0.03087712355309333\n",
            "es 0.024819269697866908\n",
            "in 0.018017946361961145\n",
            "zwei 0.017895302157496278\n",
            "Wochen 0.03003063986432607\n",
            "in 0.025940210667872093\n",
            "der 0.023251029511036282\n",
            "Bundesliga 0.05716164042458836\n",
            "wieder 0.01203980647078767\n",
            "losgehen 0.00583129451285671\n",
            "würde 0.03879455071515468\n",
            ". 0.12072620863387562\n",
            "Wir 0.019060273146967795\n",
            "lernen 0.012353933512564218\n",
            "gerade 0.00628229120688047\n",
            "alle 0.010505001215702199\n",
            ", 0.012323023127170943\n",
            "Kompromisse 0.0056848631707390965\n",
            "einzugehen 0.002722717941780326\n",
            ", 0.005047595520602355\n",
            "an 0.0018329884443071581\n",
            "die 0.0032613291405828838\n",
            "wir 0.013254898654295608\n",
            "vor 0.0036984695310786435\n",
            "Wochen 0.013122986397435385\n",
            "noch 0.001867398487968193\n",
            "nicht 0.0013720230891756517\n",
            "gedacht 0.0011624416595517478\n",
            "haben 0.005847323292139942\n",
            ". 0.0359342915081955\n",
            "Natürlich 0.0063752301906867415\n",
            "seien 0.011021791396847837\n",
            "zehn 0.004314394078787275\n",
            "bis 0.010067432806270381\n",
            "14 0.00470361136148839\n",
            "Tage 0.007221872841094629\n",
            "richtiges 0.006858679639577968\n",
            "Mannschaftstraining 0.027314170292516007\n",
            "sinnvoll 0.00564797832983223\n",
            ". 0.02234715007256007\n",
            "Aber 0.014534143045985954\n",
            "vielleicht 0.02090649367599008\n",
            "kriegen 0.023371325204447596\n",
            "wir 0.023200140591150317\n",
            "diese 0.050545713461398724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa9tlNnqvgm5"
      },
      "source": [
        "def scale_color_h_hex(c_h, scale):\n",
        "    return matplotlib.colors.to_hex(\n",
        "        matplotlib.colors.hsv_to_rgb((c_h, scale, 1)))\n",
        "\n",
        "def blue_background_hex(scale):\n",
        "    return scale_color_h_hex(0.625, scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js7LWFLMxoeA"
      },
      "source": [
        "att_html = \"<table><tr>\"\n",
        "for token, att in zip(tokens, avg_token_atts):\n",
        "  att_html += \"<td>\"\n",
        "  att_html += \"<span style=\\\"background-color: \" + blue_background_hex(att) + \"\\\">\" + token + \"</span>\"\n",
        "  att_html += \"</td>\"\n",
        "att_html += \"</tr>\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybnrhz1mzfw1",
        "outputId": "1d8d6735-0f1d-484d-efbc-baacd728ea83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 60
        }
      },
      "source": [
        "IPython.display.HTML(att_html)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><td><span style=\"background-color: #f0f4ff\">Heldt</span></td><td><span style=\"background-color: #f0f4ff\">hätte</span></td><td><span style=\"background-color: #fbfcff\">kein</span></td><td><span style=\"background-color: #fbfcff\">Problem</span></td><td><span style=\"background-color: #fbfcff\">damit</span></td><td><span style=\"background-color: #f6f8ff\">,</span></td><td><span style=\"background-color: #f7f9ff\">wenn</span></td><td><span style=\"background-color: #f9faff\">es</span></td><td><span style=\"background-color: #fafcff\">in</span></td><td><span style=\"background-color: #fafcff\">zwei</span></td><td><span style=\"background-color: #f7f9ff\">Wochen</span></td><td><span style=\"background-color: #f8faff\">in</span></td><td><span style=\"background-color: #f9fbff\">der</span></td><td><span style=\"background-color: #f0f4ff\">Bundesliga</span></td><td><span style=\"background-color: #fcfdff\">wieder</span></td><td><span style=\"background-color: #fefeff\">losgehen</span></td><td><span style=\"background-color: #f5f8ff\">würde</span></td><td><span style=\"background-color: #e0e8ff\">.</span></td><td><span style=\"background-color: #fafbff\">Wir</span></td><td><span style=\"background-color: #fcfdff\">lernen</span></td><td><span style=\"background-color: #fdfeff\">gerade</span></td><td><span style=\"background-color: #fcfdff\">alle</span></td><td><span style=\"background-color: #fcfdff\">,</span></td><td><span style=\"background-color: #fefeff\">Kompromisse</span></td><td><span style=\"background-color: #fefeff\">einzugehen</span></td><td><span style=\"background-color: #fefeff\">,</span></td><td><span style=\"background-color: #ffffff\">an</span></td><td><span style=\"background-color: #fefeff\">die</span></td><td><span style=\"background-color: #fcfcff\">wir</span></td><td><span style=\"background-color: #fefeff\">vor</span></td><td><span style=\"background-color: #fcfcff\">Wochen</span></td><td><span style=\"background-color: #ffffff\">noch</span></td><td><span style=\"background-color: #ffffff\">nicht</span></td><td><span style=\"background-color: #ffffff\">gedacht</span></td><td><span style=\"background-color: #fefeff\">haben</span></td><td><span style=\"background-color: #f6f8ff\">.</span></td><td><span style=\"background-color: #fdfeff\">Natürlich</span></td><td><span style=\"background-color: #fcfdff\">seien</span></td><td><span style=\"background-color: #fefeff\">zehn</span></td><td><span style=\"background-color: #fcfdff\">bis</span></td><td><span style=\"background-color: #fefeff\">14</span></td><td><span style=\"background-color: #fdfeff\">Tage</span></td><td><span style=\"background-color: #fdfeff\">richtiges</span></td><td><span style=\"background-color: #f8faff\">Mannschaftstraining</span></td><td><span style=\"background-color: #fefeff\">sinnvoll</span></td><td><span style=\"background-color: #f9fbff\">.</span></td><td><span style=\"background-color: #fbfcff\">Aber</span></td><td><span style=\"background-color: #fafbff\">vielleicht</span></td><td><span style=\"background-color: #f9fbff\">kriegen</span></td><td><span style=\"background-color: #f9fbff\">wir</span></td><td><span style=\"background-color: #f2f5ff\">diese</span></td></tr>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJLGG1jmzszh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}